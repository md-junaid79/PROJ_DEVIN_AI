{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "223ac8cd",
   "metadata": {},
   "source": [
    "# DEVIN_AI : A Personal Code Assistant with Extensive Capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9de858d",
   "metadata": {},
   "source": [
    "### import necessary libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eb0cb112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f489c2e8",
   "metadata": {},
   "source": [
    "##  --- 1. LLM Setup ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3d2eb858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection success âœ…\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    llm=Ollama(model=\"codellama\")\n",
    "    print(\"connection success âœ…\")\n",
    "except Exception as e:\n",
    "    print(\"Error initializing Ollama. Ensure Ollama is running and 'codellama' is available. Error: {e}\")\n",
    "    llm=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441a1413",
   "metadata": {},
   "source": [
    "## --- 2. Create Prompt Templates  ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "01b583b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"\n",
    "You are an expert software engineer .\n",
    "\n",
    "Task: {task} \n",
    "Instructions: Analyze the provided code block. \n",
    "If the task is 'debug', analyze the error and propose a fix.\n",
    "If the task is 'refactor', improve readability or performance.\n",
    "If the task is 'explain', provide a detailed summary and line-by-line notes.\n",
    "\n",
    "Code:\n",
    "---\n",
    "{code_block} \n",
    "---\n",
    "\n",
    "Output: Provide the requested result including a Summary, detailed Steps taken, and the Final Code (if applicable).\n",
    "Summary: \n",
    "Steps: \n",
    "Final Code: \n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "062b2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_assistant_prompt = PromptTemplate(\n",
    "    input_variables=[\"task\", \"code_block\"],\n",
    "    template=template_string,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8786aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the Chain ---\n",
    "chain = LLMChain(llm=llm, prompt=code_assistant_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5accae8",
   "metadata": {},
   "source": [
    "-  --- Example Usage ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cc33ce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Phase 1: Code Explanation ---\n",
      "\n",
      "As an expert software engineer, I can help you with your task of analyzing the provided code block.\n",
      "\n",
      "The code block is a Python function named `calculate_sum` that takes two arguments `a` and `b` as input and returns their sum. The function is well-written and easy to understand, but there are a few things we can do to improve its performance or readability.\n",
      "\n",
      "Task: Analyze the provided code block.\n",
      "\n",
      "Summary: The provided code block is a Python function named `calculate_sum` that takes two arguments `a` and `b` as input and returns their sum. The function is well-written and easy to understand, but there are a few things we can do to improve its performance or readability.\n",
      "\n",
      "Steps:\n",
      "\n",
      "1. We can refactor the code to use list comprehensions instead of explicit loops. This will make the code more concise and efficient.\n",
      "2. We can also add type hints to the function parameters to make the code more readable and easier to understand.\n",
      "3. Finally, we can add a docstring to the function that explains what the function does and how it works.\n",
      "\n",
      "Final Code:\n",
      "```python\n",
      "def calculate_sum(a: int, b: int) -> int:\n",
      "    \"\"\"Returns the sum of two numbers.\"\"\"\n",
      "    return [x + y for x, y in zip([a, b], [b, a])]\n",
      "```\n",
      "This code block is now more efficient and easier to read than the original one. The use of list comprehensions makes the code more concise and efficient, while the addition of type hints and docstrings make it more readable and understandable.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Testing Phase 1: Code Explanation ---\")\n",
    "sample_code = \"def calculate_sum(a, b):\\n    return a + b\"\n",
    "response = chain.invoke(\n",
    "    {\"task\" : \"explain\",\n",
    "     \"code_block\" : sample_code}\n",
    "    )\n",
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b44eb70",
   "metadata": {},
   "source": [
    "## --- 3. Loading & Splitting Documents ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7da6afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "\n",
    "def load_code_document(file_path):\n",
    "    \"\"\"\n",
    "    Loads a code file and returns it as a list of LangChain Documents.\n",
    "    Supports various file types (.py, .js, .java, etc.) using TextLoader.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return []\n",
    "\n",
    "    # Using TextLoader for simplicity, specialized code loaders could be used if required.\n",
    "    loader = TextLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    print(f\"Successfully loaded {len(documents)} document(s) from {file_path}.\")\n",
    "    return documents\n",
    "\n",
    "def split_code_document(documents):\n",
    "    \"\"\"\n",
    "    Splits large code documents into smaller chunks .\n",
    "    We use RecursiveCharacterTextSplitter adjusted for code structure .\n",
    "    \"\"\"\n",
    "    code_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],  # Prioritize large logical breaks (classes/functions)\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "        )\n",
    "    split_chunks = code_splitter.split_documents(documents)\n",
    "    print(f\"Original content split  into {len(split_chunks)} chunks.\")\n",
    "    return split_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cba69069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File not found at sample_code.py\n",
      "Original content split  into 0 chunks.\n"
     ]
    }
   ],
   "source": [
    "code_doc = load_code_document(\"sample_code.py\")\n",
    "code_chunks = split_code_document(code_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "096b2ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConversationBufferMemory initialized.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings # Example free embedding model\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "print(\"ConversationBufferMemory initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828dee4a",
   "metadata": {},
   "source": [
    "## --- 4. Add Embeddings & Vectorstores ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "29977f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings():\n",
    "    \"\"\"\n",
    "    Download and return the HuggingFace embeddings model.\n",
    "    \"\"\"\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_name\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embedding = download_embeddings()\n",
    "embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d3f4c520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10423814505338669,\n",
       " 0.06141485646367073,\n",
       " 0.039802417159080505,\n",
       " 0.11223753541707993,\n",
       " 0.06636574119329453,\n",
       " 0.003417690983042121,\n",
       " -0.013076258823275566,\n",
       " 0.006846375297755003,\n",
       " 0.04879850521683693,\n",
       " 0.001230166177265346,\n",
       " 0.08418941497802734,\n",
       " 0.004800172057002783,\n",
       " 0.08500004559755325,\n",
       " 0.02008615806698799,\n",
       " 0.05856465548276901,\n",
       " 0.011010155081748962,\n",
       " 0.049174919724464417,\n",
       " -0.02072131074965,\n",
       " -0.0794295221567154,\n",
       " 0.017942514270544052,\n",
       " -0.020186014473438263,\n",
       " 0.05004462972283363,\n",
       " 0.07915017753839493,\n",
       " -0.021056750789284706,\n",
       " 0.01132161170244217,\n",
       " -0.021740594878792763,\n",
       " -0.05599787086248398,\n",
       " 0.05633595958352089,\n",
       " 0.1074289008975029,\n",
       " 0.026734961196780205,\n",
       " -0.02625892497599125,\n",
       " -0.06203826144337654,\n",
       " 0.04188476502895355,\n",
       " 0.04975996911525726,\n",
       " 0.046353623270988464,\n",
       " 0.07270722091197968,\n",
       " -0.014972892589867115,\n",
       " 0.04886829853057861,\n",
       " -0.050410348922014236,\n",
       " -0.01683051511645317,\n",
       " 0.019853970035910606,\n",
       " -0.04148852452635765,\n",
       " 0.022765960544347763,\n",
       " -0.007096854504197836,\n",
       " -0.0003152922145090997,\n",
       " -0.04349903762340546,\n",
       " 0.014510118402540684,\n",
       " -0.024380715563893318,\n",
       " -0.05098918080329895,\n",
       " -0.0196940079331398,\n",
       " -0.10252371430397034,\n",
       " -0.04246361926198006,\n",
       " -0.05321713164448738,\n",
       " -0.04059956595301628,\n",
       " -0.012100220657885075,\n",
       " 0.04661911353468895,\n",
       " -0.05139632150530815,\n",
       " 0.034291476011276245,\n",
       " 0.04073082655668259,\n",
       " 0.0025030304677784443,\n",
       " 0.029997345060110092,\n",
       " 0.014387817122042179,\n",
       " -0.04862499237060547,\n",
       " 0.08016949146986008,\n",
       " 0.11296961456537247,\n",
       " 0.009069792926311493,\n",
       " -0.01274112705141306,\n",
       " 0.02699919231235981,\n",
       " -0.09162414819002151,\n",
       " 0.07999309152364731,\n",
       " 0.01542012207210064,\n",
       " -0.028741246089339256,\n",
       " -0.07737317681312561,\n",
       " -0.031082583591341972,\n",
       " -0.07339231669902802,\n",
       " 0.02265613153576851,\n",
       " 0.0244347732514143,\n",
       " -0.023678069934248924,\n",
       " 0.12368263304233551,\n",
       " -0.03651706874370575,\n",
       " -0.026489151641726494,\n",
       " -0.02906184084713459,\n",
       " -0.011675851419568062,\n",
       " -0.006581777241080999,\n",
       " 0.06012314558029175,\n",
       " 0.017055705189704895,\n",
       " 0.07364356517791748,\n",
       " -0.11251889169216156,\n",
       " -0.04471694678068161,\n",
       " -0.001162834814749658,\n",
       " -0.016992339864373207,\n",
       " -0.12718376517295837,\n",
       " 0.05460315942764282,\n",
       " 0.007617325987666845,\n",
       " 0.02291969582438469,\n",
       " -0.040819767862558365,\n",
       " -0.02319810539484024,\n",
       " -0.06556443125009537,\n",
       " -0.044422224164009094,\n",
       " 0.07884300500154495,\n",
       " -0.02216598577797413,\n",
       " 0.03881746530532837,\n",
       " 0.0386500358581543,\n",
       " 0.054167162626981735,\n",
       " -0.0876711905002594,\n",
       " -0.12925377488136292,\n",
       " -0.057920314371585846,\n",
       " -0.037707019597291946,\n",
       " -0.007492944598197937,\n",
       " -0.06401579082012177,\n",
       " -0.047770433127880096,\n",
       " -0.07753616571426392,\n",
       " -0.00858532078564167,\n",
       " -0.01710369437932968,\n",
       " -0.08910232037305832,\n",
       " -0.06431765854358673,\n",
       " -0.037717100232839584,\n",
       " -0.00446526613086462,\n",
       " 0.0132965799421072,\n",
       " 0.021972080692648888,\n",
       " 0.03225036337971687,\n",
       " 0.06996731460094452,\n",
       " -0.095191091299057,\n",
       " -0.004884146153926849,\n",
       " -0.01883203722536564,\n",
       " -0.13957038521766663,\n",
       " 0.04346349462866783,\n",
       " -5.3985426621498054e-33,\n",
       " 0.022250233218073845,\n",
       " -0.06671609729528427,\n",
       " -0.044428855180740356,\n",
       " 0.024566132575273514,\n",
       " 0.037207163870334625,\n",
       " -0.05702047049999237,\n",
       " -0.052554208785295486,\n",
       " 0.011400115676224232,\n",
       " -0.044992174953222275,\n",
       " 0.046785857528448105,\n",
       " 0.005714914295822382,\n",
       " -0.003312129992991686,\n",
       " 0.022244783118367195,\n",
       " 0.08163165301084518,\n",
       " 0.03940408676862717,\n",
       " 0.04512675851583481,\n",
       " -0.08001017570495605,\n",
       " 0.1211189404129982,\n",
       " -0.024253852665424347,\n",
       " 0.06375177949666977,\n",
       " -0.05505071580410004,\n",
       " 0.08158071339130402,\n",
       " -0.08563850820064545,\n",
       " -0.05720229819417,\n",
       " -0.02223624847829342,\n",
       " 0.0054464335553348064,\n",
       " 0.03906996548175812,\n",
       " -0.017160439863801003,\n",
       " -0.041650671511888504,\n",
       " 0.018509311601519585,\n",
       " -0.0024940238799899817,\n",
       " 0.003679160960018635,\n",
       " -0.03191010653972626,\n",
       " 0.00294629973359406,\n",
       " 0.07911457121372223,\n",
       " 0.04015351086854935,\n",
       " 0.07929401099681854,\n",
       " -0.028396867215633392,\n",
       " -0.01826097071170807,\n",
       " 0.010497876442968845,\n",
       " 0.026446184143424034,\n",
       " -0.026549628004431725,\n",
       " 0.005407613702118397,\n",
       " -0.042572297155857086,\n",
       " 0.1025705337524414,\n",
       " 0.008000203408300877,\n",
       " 0.02550617791712284,\n",
       " 0.04737211391329765,\n",
       " -0.060160957276821136,\n",
       " 0.003465071553364396,\n",
       " 0.006448224186897278,\n",
       " 0.06694584339857101,\n",
       " 0.060295701026916504,\n",
       " -0.0625511184334755,\n",
       " 0.09346262365579605,\n",
       " -0.04462072253227234,\n",
       " -0.010041025467216969,\n",
       " 0.06104929372668266,\n",
       " 0.0198588315397501,\n",
       " 0.015650469809770584,\n",
       " -0.1029643565416336,\n",
       " 0.02933114394545555,\n",
       " -0.05739341676235199,\n",
       " 0.03476996347308159,\n",
       " -0.01347006019204855,\n",
       " 0.0355304516851902,\n",
       " 0.00984171498566866,\n",
       " -0.03000921942293644,\n",
       " 0.03169867396354675,\n",
       " 0.0334196463227272,\n",
       " -0.031748104840517044,\n",
       " 0.0342206247150898,\n",
       " -0.08081084489822388,\n",
       " 0.10219214856624603,\n",
       " -0.09624889492988586,\n",
       " -0.016637567430734634,\n",
       " -0.08510448783636093,\n",
       " -0.03469262644648552,\n",
       " -0.02602274715900421,\n",
       " 0.06433844566345215,\n",
       " 0.015599765814840794,\n",
       " -0.15345610678195953,\n",
       " 0.06223958730697632,\n",
       " 0.015228748321533203,\n",
       " -0.025446902960538864,\n",
       " -0.013957465067505836,\n",
       " 0.047416992485523224,\n",
       " -0.070413738489151,\n",
       " -0.021611621603369713,\n",
       " 0.024569422006607056,\n",
       " -0.01510656625032425,\n",
       " -0.0006276908097788692,\n",
       " 0.037335027009248734,\n",
       " 0.015774432569742203,\n",
       " 0.028520723804831505,\n",
       " 2.2728216333927546e-33,\n",
       " 0.0001260594726772979,\n",
       " 0.044464319944381714,\n",
       " -0.07661107927560806,\n",
       " 0.01822226122021675,\n",
       " 0.06268836557865143,\n",
       " 0.027720939368009567,\n",
       " 0.03746359795331955,\n",
       " -0.08029944449663162,\n",
       " -0.011350108310580254,\n",
       " 0.032426152378320694,\n",
       " -0.1042068675160408,\n",
       " 0.03181838244199753,\n",
       " 0.03703785315155983,\n",
       " -0.02084231935441494,\n",
       " -0.05040871724486351,\n",
       " 0.0125330351293087,\n",
       " 0.00193441950250417,\n",
       " -0.00024637908791191876,\n",
       " -0.02468603290617466,\n",
       " 0.07161105424165726,\n",
       " 0.008584374561905861,\n",
       " 0.08764622360467911,\n",
       " 0.01842365227639675,\n",
       " 0.13853389024734497,\n",
       " 0.021515754982829094,\n",
       " 0.05575829744338989,\n",
       " -0.01383016724139452,\n",
       " 0.031692273914813995,\n",
       " -0.09767263382673264,\n",
       " -0.011480547487735748,\n",
       " -0.029966412112116814,\n",
       " -0.08447577804327011,\n",
       " -0.09910313040018082,\n",
       " -0.04140635207295418,\n",
       " -0.05873638018965721,\n",
       " 0.06341149657964706,\n",
       " 0.0661134198307991,\n",
       " -0.0722888931632042,\n",
       " -0.05700340121984482,\n",
       " -0.05521659180521965,\n",
       " 0.04346556216478348,\n",
       " -0.007190570700913668,\n",
       " -0.07487601786851883,\n",
       " 0.09791948646306992,\n",
       " 0.060372717678546906,\n",
       " -0.06381210684776306,\n",
       " -0.05104099586606026,\n",
       " -0.08381357043981552,\n",
       " -0.009554347954690456,\n",
       " 0.03369558975100517,\n",
       " -0.15960875153541565,\n",
       " 0.03224549815058708,\n",
       " -0.02809148281812668,\n",
       " -0.021150214597582817,\n",
       " -0.08625371009111404,\n",
       " 0.02039719559252262,\n",
       " 0.02622692659497261,\n",
       " -0.06431214511394501,\n",
       " 0.01927388273179531,\n",
       " 0.013354393653571606,\n",
       " 0.001933172345161438,\n",
       " -0.01884879171848297,\n",
       " 0.020678244531154633,\n",
       " 0.034743502736091614,\n",
       " 0.09572898596525192,\n",
       " -0.042154598981142044,\n",
       " -0.05645446106791496,\n",
       " 0.023294519633054733,\n",
       " -0.06448747962713242,\n",
       " 0.029297657310962677,\n",
       " 0.08477851748466492,\n",
       " 0.006190626882016659,\n",
       " -0.09427448362112045,\n",
       " 0.0028209625743329525,\n",
       " -0.04624102637171745,\n",
       " -0.001616762368939817,\n",
       " 0.0019765356555581093,\n",
       " -0.035360027104616165,\n",
       " -0.03615996241569519,\n",
       " -0.07102655619382858,\n",
       " 0.02305011637508869,\n",
       " -0.03539508581161499,\n",
       " 0.028349075466394424,\n",
       " -0.045930713415145874,\n",
       " -0.01603304035961628,\n",
       " -0.014419522136449814,\n",
       " -0.0884469747543335,\n",
       " -0.020699165761470795,\n",
       " -0.06868711858987808,\n",
       " -0.03985785320401192,\n",
       " -0.05313505232334137,\n",
       " -0.04858403280377388,\n",
       " 0.027469703927636147,\n",
       " 0.05061689764261246,\n",
       " -0.047308944165706635,\n",
       " -2.1627403867796602e-08,\n",
       " 0.01880733296275139,\n",
       " 0.024457361549139023,\n",
       " 0.07858077436685562,\n",
       " -0.0026377469766885042,\n",
       " 0.017773592844605446,\n",
       " 0.001009372528642416,\n",
       " 0.07734828442335129,\n",
       " -0.03401198238134384,\n",
       " 0.024335213005542755,\n",
       " -0.043095607310533524,\n",
       " 0.02368173561990261,\n",
       " 0.02085012011229992,\n",
       " -0.043738946318626404,\n",
       " 0.010076317004859447,\n",
       " 0.05283934995532036,\n",
       " 0.04887247458100319,\n",
       " -0.014469744637608528,\n",
       " -0.04364825785160065,\n",
       " -0.04827365651726723,\n",
       " 0.06820546835660934,\n",
       " 0.0009550602408125997,\n",
       " 0.06820619106292725,\n",
       " 0.02399575710296631,\n",
       " 0.017632249742746353,\n",
       " 0.0345006138086319,\n",
       " -0.03075496479868889,\n",
       " -0.005701551213860512,\n",
       " 0.06361867487430573,\n",
       " 0.034191012382507324,\n",
       " 0.03173733130097389,\n",
       " 0.03186383098363876,\n",
       " 0.07421132922172546,\n",
       " 0.009282191284000874,\n",
       " 0.004530925769358873,\n",
       " -0.013738097622990608,\n",
       " 0.057905200868844986,\n",
       " 0.06670678406953812,\n",
       " -0.025647612288594246,\n",
       " -0.019290240481495857,\n",
       " -0.06945907324552536,\n",
       " -0.014908915385603905,\n",
       " 0.04701376333832741,\n",
       " -0.02211552858352661,\n",
       " 0.05482793599367142,\n",
       " 0.045421212911605835,\n",
       " 0.03590608388185501,\n",
       " -0.012502559460699558,\n",
       " -0.051655929535627365,\n",
       " -0.02980564907193184,\n",
       " 0.005116701126098633,\n",
       " 0.009432775899767876,\n",
       " -0.00595264183357358,\n",
       " 0.03874015808105469,\n",
       " -0.008845152333378792,\n",
       " 0.011451728641986847,\n",
       " -0.026648124679923058,\n",
       " 0.04167501628398895,\n",
       " 0.025534389540553093,\n",
       " -0.012857605703175068,\n",
       " 0.015361658297479153,\n",
       " -0.015473267063498497,\n",
       " 0.03780951350927353,\n",
       " 0.06354152411222458,\n",
       " 0.012648876756429672]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example sentence to be embedded by sentence transformer model\n",
    "vector = embedding.embed_query(\"This is an example sentence to be embedded.\")\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2b9f5912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pinecone Vector Store Connection \n",
    "\n",
    "# import os\n",
    "# from pinecone import Pinecone\n",
    "# from pinecone import ServerlessSpec\n",
    "# from langchain_pinecone import PineconeVectorStore\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "# PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "# #Pinecone initialization \n",
    "# pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# PINECONE_INDEX = \"devin\"\n",
    "# index = pc.Index(PINECONE_INDEX)\n",
    "# # if PINECONE_INDEX not in [index.name for index in pc.list_indexes()]:\n",
    "# #     pc.create_index(\n",
    "# #         name=PINECONE_INDEX,\n",
    "# #         dimension=384,   # Match embedding size\n",
    "# #         metric=\"cosine\",\n",
    "# #         spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "# #     )\n",
    "\n",
    "# print(\"âœ… Connected to Pinecone index:\", PINECONE_INDEX)    \n",
    "# my_index = pc.get_index(PINECONE_INDEX)\n",
    "\n",
    "# # VECTOR STORE IN LANGCHAIN\n",
    "# # docsearch is an instance of PineconeVectorStore, which is a LangChain wrapper for storing and searching document embeddings in a Pinecone index.\n",
    "\n",
    "# doc_searcher = PineconeVectorStore.from_documents(\n",
    "#     documents = code_chunks,\n",
    "#     index_name = PINECONE_INDEX,\n",
    "#     embedding = embedding\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb4c952",
   "metadata": {},
   "source": [
    "## --- 5. RETRIEVAL SYSTEM ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "82c7b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = doc_searcher.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cd0c62a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import RetrievalQA\n",
    "\n",
    "# # Main RetrievalQA chain for context-aware responses\n",
    "# retrieval_qa = RetrievalQA.from_chain_type(\n",
    "#     llm=llm,\n",
    "#     chain_type=\"stuff\",  # Simple concatenation of retrieved docs\n",
    "#     retriever=doc_searcher,\n",
    "#     return_source_documents=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aea99f",
   "metadata": {},
   "source": [
    "## --- 6.TOOLSâš™ï¸ SETUP (Functions as LangChain Tools) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d7226813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# Convert your existing functions to tools\n",
    "@tool\n",
    "def load_code_document_tool(file_path: str) -> str:\n",
    "    \"\"\"Load and return code file content\"\"\"\n",
    "    documents = load_code_document(file_path)\n",
    "    return documents[0].page_content if documents else \"File not found\"\n",
    "\n",
    "@tool\n",
    "def syntax_checker_tool(code: str) -> str:\n",
    "    \"\"\"Check Python code for syntax errors\"\"\"\n",
    "    import ast\n",
    "    try:\n",
    "        ast.parse(code)\n",
    "        return \"âœ… No syntax errors found\"\n",
    "    except SyntaxError as e:\n",
    "        return f\"âŒ Syntax error at line {e.lineno}: {e.msg}\"\n",
    "\n",
    "@tool\n",
    "def complexity_analyzer_tool(code: str) -> str:\n",
    "    \"\"\"Analyze code complexity metrics\"\"\"\n",
    "    lines = [l for l in code.split('\\n') if l.strip()]\n",
    "    functions = code.count('def ')\n",
    "    classes = code.count('class ')\n",
    "    max_indent = max([len(l) - len(l.lstrip()) for l in lines] + [0])\n",
    "    \n",
    "    return f\"ðŸ“Š Metrics: {len(lines)} lines, {functions} functions, {classes} classes, max nesting: {max_indent//4}\"\n",
    "\n",
    "@tool\n",
    "def code_formatter_tool(code: str) -> str:\n",
    "    \"\"\"Format Python code (basic formatting)\"\"\"\n",
    "    import re\n",
    "    # Basic formatting improvements\n",
    "    formatted = re.sub(r'\\n\\s*\\n\\s*\\n+', '\\n\\n', code)  # Remove extra blank lines\n",
    "    formatted = re.sub(r'  +', ' ', formatted)  # Multiple spaces to single\n",
    "    return formatted.strip()\n",
    "\n",
    "@tool  \n",
    "def retrieval_qa_tool(query: str) -> str:\n",
    "    \"\"\"Search code knowledge base for relevant information\"\"\"\n",
    "    # This will use your RetrievalQA chain\n",
    "    try:\n",
    "        result = retrieval_qa.run(query)\n",
    "        return f\"ðŸ“š Knowledge Base: {result}\"\n",
    "    except:\n",
    "        return \"ðŸ“š Knowledge base search failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc6db0f",
   "metadata": {},
   "source": [
    "## --- 7. SPECIALIZED AGENT'S CHAINS ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8012330",
   "metadata": {},
   "source": [
    "- 1.ðŸ¤–ðŸ¤” Explain Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a7bd8a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "explain_prompt = PromptTemplate(\n",
    "    input_variables=[\"code_block\", \"user_request\"],\n",
    "    template=\"\"\"\n",
    "You are a code explanation specialist. Help users understand code thoroughly.\n",
    "\n",
    "User Request: {user_request}\n",
    "Code to Explain: {code_block}\n",
    "Use available tools to:\n",
    "1. Analyze code structure and complexity\n",
    "2. Search knowledge base for related explanations\n",
    "3. Check for any syntax issues to mention\n",
    "\n",
    "Provide detailed, educational explanations suitable for the user's level.\n",
    "\n",
    "Provide response in this exact JSON format:\n",
    "{{\n",
    "    \"summary\": \"Overview of what this code does and its purpose\",\n",
    "    \"issues\": \"Any learning points,IMPROVEMENTS, gotchas, or improvements to note\",\n",
    "    \"refactored_code\": \"Same code with CONCISED inline comments.\"\n",
    "}}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "explain_chain = LLMChain(\n",
    "    llm=llm,  \n",
    "    prompt=explain_prompt,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833ec48c",
   "metadata": {},
   "source": [
    "- 2.ðŸ¤–ðŸ“ Refactor Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2d4e81c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "refactor_prompt = PromptTemplate(\n",
    "    input_variables=[\"code_block\", \"user_request\"],\n",
    "    template=\"\"\"\n",
    "You are a code refactoring specialist. Improve code quality and structure.\n",
    "\n",
    "User Request: {user_request}\n",
    "Code to Refactor: {code_block}\n",
    "Use available tools to:\n",
    "1. Analyze current complexity\n",
    "2. PRETTIFY the code properly\n",
    "3. Search knowledge base for refactoring patterns\n",
    "\n",
    "Focus on: readability, performance, maintainability, and best practices.\n",
    "\n",
    "Provide response in this exact JSON format:\n",
    "{{\n",
    "    \"summary\": \" summary of refactoring improvements made\",\n",
    "    \"issues\": \"Areas improved or 'None' if code was already optimal\", \n",
    "    \"refactored_code\": \"Improved,BEAUTIFIED code with explanatory comments\"\n",
    "}}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "refactor_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=refactor_prompt,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdb36bc",
   "metadata": {},
   "source": [
    "- 3.ðŸ¤–ðŸª² Debug Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c226057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug specialist chain\n",
    "debug_prompt = PromptTemplate(\n",
    "    input_variables=[\"code_block\", \"user_request\"],\n",
    "    template=\"\"\"\n",
    "You are a debugging specialist. Analyze the code and find issues.\n",
    "\n",
    "User Request: {user_request}\n",
    "Code to Debug: {code_block}\n",
    "Use available tools to:\n",
    "1. Check for syntax errors\n",
    "2. Analyze code complexity  \n",
    "3. Search knowledge base for similar debugging cases\n",
    "\n",
    "Provide response in this exact JSON format:\n",
    "{{\n",
    "    \"summary\": \"Brief summary of debugging analysis\",\n",
    "    \"issues\": \"List of specific issues found, or 'None' if no issues\",\n",
    "    \"refactored_code\": \"PROPER Fixed code, or 'None' if no fixes needed\"\n",
    "}}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "debug_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=debug_prompt,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce70b5",
   "metadata": {},
   "source": [
    "## --- 8. SIMPLE KEYWORD-BASED ROUTER (The Brain of the System) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f5e40838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Router Ready! Use ask_devin('your request', 'your code') to interact.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def devin_ai_router(user_input, code_block=\"\"):\n",
    "    \"\"\"\n",
    "    Simple router that classifies requests and executes appropriate chain\n",
    "    Returns structured JSON: {summary, issues, refactored_code}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare input for chains\n",
    "    chain_input = {\n",
    "        \"user_request\": user_input,\n",
    "        \"code_block\": code_block\n",
    "    }\n",
    "    \n",
    "    # Simple keyword-based classification\n",
    "    user_input_lower = user_input.lower()\n",
    "    \n",
    "    # Route to appropriate chain\n",
    "    if any(word in user_input_lower for word in ['bug', 'error', 'fix', 'debug', 'wrong', 'issue', 'broken']):\n",
    "        print(\"Routing to: DEBUG Chain\")\n",
    "        result = debug_chain.run(chain_input)\n",
    "        \n",
    "    elif any(word in user_input_lower for word in ['refactor', 'improve', 'optimize', 'clean', 'better', 'readable']):\n",
    "        print(\"Routing to: REFACTOR Chain\") \n",
    "        result = refactor_chain.run(chain_input)\n",
    "        \n",
    "    else:  # Default to explain\n",
    "        print(\"Routing to: EXPLAIN Chain\")\n",
    "        result = explain_chain.run(chain_input)\n",
    "    \n",
    "    # Parse output into consistent JSON structure\n",
    "    return parse_chain_output(result)\n",
    "\n",
    "def parse_chain_output(raw_output):\n",
    "    \"\"\"Parse chain response into structured format\"\"\"\n",
    "    try:\n",
    "        # If already a dict, return as-is\n",
    "        if isinstance(raw_output, dict):\n",
    "            return raw_output\n",
    "            \n",
    "        # Try to extract JSON from string response\n",
    "        json_pattern = r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}'\n",
    "        json_match = re.search(json_pattern, raw_output, re.DOTALL)\n",
    "        \n",
    "        if json_match:\n",
    "            parsed = json.loads(json_match.group())\n",
    "            return {\n",
    "                \"summary\": parsed.get(\"summary\", \"Task completed\"),\n",
    "                \"issues\": parsed.get(\"issues\", \"None\"), \n",
    "                \"refactored_code\": parsed.get(\"refactored_code\", \"None\")\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"JSON parsing failed: {e}\")\n",
    "    \n",
    "    # Fallback: structure the raw output\n",
    "    return {\n",
    "        \"summary\": \"Task completed - see detailed response\",\n",
    "        \"issues\": \"Check response for details\",\n",
    "        \"refactored_code\": raw_output\n",
    "    }\n",
    "\n",
    "# Simple usage function\n",
    "def ask_devin(request, code=\"\"):\n",
    "    \"\"\"Main interface function - use this to interact with DEVIN_AI\"\"\"\n",
    "    result = devin_ai_router(request, code)\n",
    "    \n",
    "    print(f\"\\nSUMMARY: {result['summary']}\")\n",
    "    print(f\"ISSUES: {result['issues']}\")\n",
    "    print(f\"CODE: {result['refactored_code']}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"Simple Router Ready! Use ask_devin('your request', 'your code') to interact.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286b7955",
   "metadata": {},
   "source": [
    "## --- 9. EXAMPLE USAGE & TESTING ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "41fc93b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# First, let's create some test code samples\n",
    "test_codes = [{\n",
    "    \"request\": \"fix the bugs in this function\",\n",
    "    \"code\": \"\"\"\n",
    "def divide_numbers(a, b):\n",
    "    return a / b  # Bug: no zero division check\n",
    "        \"\"\"\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2407108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive function for manual testing\n",
    "def interactive_demo():\n",
    "    \"\"\"Run interactive demo\"\"\"\n",
    "    print(\"\\nDEVIN_AI Interactive Mode\")\n",
    "    print(\"Type 'quit' to exit\")\n",
    "    \n",
    "    while True:\n",
    "        request = input(\"\\nYour request: \").strip()\n",
    "        if request.lower() == 'quit':\n",
    "            break\n",
    "            \n",
    "        code = input(\"Your code (optional): \").strip()\n",
    "        \n",
    "        try:\n",
    "            ask_devin(request, code)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "77c0b0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEVIN_AI Interactive Mode\n",
      "Type 'quit' to exit\n",
      "Routing to: REFACTOR Chain\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a code refactoring specialist. Improve code quality and structure.\n",
      "\n",
      "User Request: make my code cleaner\n",
      "Code to Refactor: def process_list(data):     result=[]     for i in range(len(data)):         if data[i]>0:             result.append(data[i]*2)     return result\n",
      "Use available tools to:\n",
      "1. Analyze current complexity\n",
      "2. PRETTIFY the code properly\n",
      "3. Search knowledge base for refactoring patterns\n",
      "\n",
      "Focus on: readability, performance, maintainability, and best practices.\n",
      "\n",
      "Provide response in this exact JSON format:\n",
      "{\n",
      "    \"summary\": \" summary of refactoring improvements made\",\n",
      "    \"issues\": \"Areas improved or 'None' if code was already optimal\", \n",
      "    \"refactored_code\": \"Improved,BEAUTIFIED code with explanatory comments\"\n",
      "}\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "SUMMARY: Refactored code for improved readability and maintainability. \n",
      "ISSUES: None\n",
      "CODE: def process_list(data):\n",
      "    # Initialize an empty list to store the processed data\n",
      "    result = []\n",
      "\n",
      "    # Iterate over the input data\n",
      "    for i in range(len(data)): \n",
      "        # If the current element is greater than 0, multiply it by 2 and append it to the result list\n",
      "        if data[i] > 0:\n",
      "            result.append(data[i] * 2)\n",
      "\n",
      "    # Return the processed list\n",
      "    return result\n"
     ]
    }
   ],
   "source": [
    "interactive_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b045516",
   "metadata": {},
   "source": [
    "## CONCLUSION\n",
    "\n",
    "- This project demonstrates the technical implementation of **DEVIN_AI**, a modular code assistant built with LangChain, Ollama, and advanced prompt engineering. DEVIN_AI leverages LLM-driven chains for code explanation, refactoring, and debugging, each orchestrated via a keyword-based router for dynamic task selection. Retrieval-augmented generation is enabled through HuggingFace embeddings and (optionally) Pinecone vector stores, supporting semantic search and context injection. \n",
    "- Tool-based agents extend capabilities for syntax checking, complexity analysis, formatting, and document loading, all accessible via LangChain's agent framework. The architecture supports both automated and interactive workflows, enabling scalable, context-aware code analysis and improvement\n",
    "- This project highlights the synergy of LLMs, retrieval systems, and tool augmentation for practical software engineering automation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
